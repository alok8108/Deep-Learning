{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1ckB_TTvKOdb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transforming the dataset"
      ],
      "metadata": {
        "id": "G0lEMXiV0nMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_image=transforms.Compose(\n",
        "    [\n",
        "    torchvision.transforms.GaussianBlur(kernel_size=3, sigma=(0.1,2)),\n",
        "    torchvision.transforms.RandomRotation(10),\n",
        "    torchvision.transforms.ToTensor()\n",
        "    ]\n",
        "    )"
      ],
      "metadata": {
        "id": "VIwF7VsK0tkT"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up Train and Test Dataset"
      ],
      "metadata": {
        "id": "LTHSuvWCKwjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data= torchvision.datasets.CIFAR10(root=\"data\",\n",
        "                                              train=True,\n",
        "                                              download=True,\n",
        "                                              transform=transform_image,\n",
        "                                              target_transform=None\n",
        "                                              )\n",
        "test_data= torchvision.datasets.CIFAR10(root=\"data\",\n",
        "                                              train=False,\n",
        "                                              download=True,\n",
        "                                              transform=transform_image,\n",
        "                                              target_transform=None\n",
        "                                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgFQS3nuK9hb",
        "outputId": "7d138d49-48e6-4f03-c367-5ff27ed14cd7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataLoader and minibatches"
      ],
      "metadata": {
        "id": "DIMH2Y3bq2g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_full = torchvision.datasets.FashionMNIST(data_folder, train = True, download = True, transform = transforms.ToTensor())\n",
        "# # Selecting classes 7, 2, 5 and 6\n",
        "# idx = (dataset_full.targets==7) | (dataset_full.targets==2) | (dataset_full.targets==5) | (dataset_full.targets==6)\n",
        "# dataset_full.targets = dataset_full.targets[idx]\n",
        "# dataset_full.data = dataset_full.data[idx]"
      ],
      "metadata": {
        "id": "mCUw5Ijvhmon"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting classes 0, 2, 4,6 and 8 in train data\n",
        "idx0 = torch.tensor(train_data.targets) == 0\n",
        "idx2 = torch.tensor(train_data.targets) == 2\n",
        "idx4 = torch.tensor(train_data.targets) == 4\n",
        "idx6 = torch.tensor(train_data.targets) == 6\n",
        "idx8 = torch.tensor(train_data.targets) == 8\n",
        "\n",
        "train_mask= idx0 | idx2 | idx4 | idx6 | idx8\n",
        "train_indices = train_mask.nonzero().reshape(-1) #a list of indices which has true for either 0, 2, 4,6 or 8\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "train_subset = Subset(train_data, train_indices)  # make a subset\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_data = DataLoader(train_subset, shuffle=False, batch_size=32)\n"
      ],
      "metadata": {
        "id": "BVj8O-yedjSr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting classes 0, 2, 4,6 and 8 in test data\n",
        "idx0 = torch.tensor(test_data.targets) == 0\n",
        "idx2 = torch.tensor(test_data.targets) == 2\n",
        "idx4 = torch.tensor(test_data.targets) == 4\n",
        "idx6 = torch.tensor(test_data.targets) == 6\n",
        "idx8 = torch.tensor(test_data.targets) == 8\n",
        "\n",
        "test_mask= idx0 | idx2 | idx4 | idx6 | idx8\n",
        "test_indices = test_mask.nonzero().reshape(-1) #a list of indices which has true for either 0, 2, 4,6 or 8\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "test_subset = Subset(test_data, test_indices)  # make a subset\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "test_data = DataLoader(test_subset, shuffle=False, batch_size=32)\n"
      ],
      "metadata": {
        "id": "B1XSHIdnpRjj"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in test_data:\n",
        "  print(image.shape)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gygpefhxeiG6",
        "outputId": "a3486960-77d8-4b66-b898-6cf8b1de5e49"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGJSvKrbLX0_",
        "outputId": "9b2d647e-3806-48df-e338-9af3e8bff709"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(782, 157)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image,label = next(iter(train_data))"
      ],
      "metadata": {
        "id": "KrhELHtiL3_m"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape,label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUtpVGDoL7kF",
        "outputId": "27ce6db1-aba8-4b26-e760-00e5aa9362b9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 32, 32]),\n",
              " tensor([6, 4, 2, 8, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 0, 0, 4, 0, 2, 2, 2, 2, 0, 2,\n",
              "         2, 2, 4, 8, 2, 4, 8, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label)\n",
        "#image.resize(32,32,3)\n",
        "plt.imshow(image[0].permute(1, 2, 0))\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "OfVHU7TfNhN0",
        "outputId": "c73da32d-e2d6-4ff3-c246-307af3e82150"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 4, 2, 8, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 0, 0, 4, 0, 2, 2, 2, 2, 0, 2,\n",
            "        2, 2, 4, 8, 2, 4, 8, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names= train_data.dataset.dataset.classes  #the class_names is a list containing the names of all classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2T_KNSHL-6q",
        "outputId": "c502aa05-9af4-4ecf-fb49-37492beba706"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the class names to class indexes so that we can use it later\n",
        "class_to_idx= train_data.dataset.dataset.class_to_idx\n",
        "class_to_idx "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlZdoIQMKqP",
        "outputId": "3f30f85d-1825-42b0-ef79-7f9d03d1b420"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airplane': 0,\n",
              " 'automobile': 1,\n",
              " 'bird': 2,\n",
              " 'cat': 3,\n",
              " 'deer': 4,\n",
              " 'dog': 5,\n",
              " 'frog': 6,\n",
              " 'horse': 7,\n",
              " 'ship': 8,\n",
              " 'truck': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader and miniBatches"
      ],
      "metadata": {
        "id": "e8CrrHjvMYk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size= 32\n",
        "# train_dataloader= DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_dataloader= DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "mQW6mBA0NBOF"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nobcLF_zRrJW",
        "outputId": "1bd2bb0c-0b80-40d2-f578-a59736eebf62"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "782"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35KuR6bwR4to",
        "outputId": "d272deb4-47b7-4ec8-ec59-37d003d68937"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up the device"
      ],
      "metadata": {
        "id": "4F9kOvTheXDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup device agnoistic code\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-Oc5qweheXRE",
        "outputId": "8d2da7d3-a3b7-41c7-e76b-7b86ef6caf03"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "KgqsbTIGYDw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARModel(nn.Module):\n",
        "  def __init__(self, input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_lay_1=nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_1=nn.ReLU()\n",
        "    self.conv_lay_2=nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_2=nn.ReLU()\n",
        "    self.conv_lay_3=nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_3 =nn.ReLU()\n",
        "    self.conv_lay_4=nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_4=nn.ReLU()\n",
        "    self.conv_lay_5=nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_5=nn.ReLU()\n",
        "    self.conv_lay_6=nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1)\n",
        "    self.relu_lay_6=nn.ReLU()\n",
        "    self.max_lay_1=nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=12*16*16,\n",
        "                  out_features=1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=1024,\n",
        "                  out_features=5)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x= self.conv_lay_1(x)\n",
        "    x=self.relu_lay_1(x)\n",
        "    x= self.conv_lay_2(x)\n",
        "    x=self.relu_lay_2(x)\n",
        "    x= self.conv_lay_3(x)\n",
        "    x=self.relu_lay_3(x)\n",
        "    x= self.conv_lay_4(x)\n",
        "    x=self.relu_lay_4(x)\n",
        "    x= self.conv_lay_5(x)\n",
        "    x=self.relu_lay_5(x)\n",
        "    x= self.conv_lay_6(x)\n",
        "    x=self.relu_lay_6(x)\n",
        "    x=self.max_lay_1(x)\n",
        "    #print(f\"shape of conv_block_6{x.shape}\")\n",
        "    x=self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "6cOgOzTTYLOT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0= CIFARModel(input_shape=3,\n",
        "                    hidden_units=12,\n",
        "                    output_shape= len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "mPgG_hMMdRn3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss function and Accuracy function\n"
      ],
      "metadata": {
        "id": "spGD-ZHhR-xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "vYi97dK9WSpb"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn= nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.SGD(params= model_0.parameters(),\n",
        "                           lr=0.1)"
      ],
      "metadata": {
        "id": "--m0LzRpXfOE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hamMd-wjYoCm"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Weight Initialization\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_1.weight).to(device)\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_2.weight).to(device)\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_3.weight).to(device)\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_4.weight).to(device)\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_5.weight).to(device)\n",
        "torch.nn.init.kaiming_uniform_(model_0.conv_lay_6.weight).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK_KmqqAXUGg",
        "outputId": "b75b0d1d-84fb-4c4c-abc8-0fa326f48ab7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-0.0554, -0.0422,  0.0270],\n",
              "          [-0.1697, -0.1974,  0.1127],\n",
              "          [ 0.1872, -0.0519,  0.0649]],\n",
              "\n",
              "         [[-0.0158,  0.0702, -0.2332],\n",
              "          [-0.1918, -0.1290,  0.1313],\n",
              "          [ 0.2075, -0.1852, -0.0577]],\n",
              "\n",
              "         [[ 0.0709, -0.1869, -0.2317],\n",
              "          [-0.1342, -0.2236, -0.2277],\n",
              "          [-0.0687,  0.0731,  0.1947]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1370, -0.1872, -0.0680],\n",
              "          [-0.0038, -0.2026,  0.0158],\n",
              "          [-0.0787,  0.0336, -0.0622]],\n",
              "\n",
              "         [[-0.1944,  0.0358,  0.1159],\n",
              "          [-0.0213,  0.0874, -0.2234],\n",
              "          [-0.0056,  0.0402, -0.0502]],\n",
              "\n",
              "         [[ 0.0405, -0.1648, -0.1822],\n",
              "          [-0.0145,  0.0595,  0.1907],\n",
              "          [ 0.0456,  0.1056,  0.1479]]],\n",
              "\n",
              "\n",
              "        [[[-0.1675,  0.1165, -0.1636],\n",
              "          [-0.0517,  0.0679, -0.2027],\n",
              "          [ 0.0797, -0.2212,  0.1589]],\n",
              "\n",
              "         [[ 0.1172,  0.1401,  0.1179],\n",
              "          [ 0.1037,  0.1597,  0.1226],\n",
              "          [ 0.1601,  0.1751,  0.0403]],\n",
              "\n",
              "         [[-0.2233, -0.0791, -0.0035],\n",
              "          [-0.0280,  0.1087, -0.0336],\n",
              "          [-0.1803,  0.0859,  0.1842]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1586,  0.1624,  0.0134],\n",
              "          [ 0.2322,  0.1377,  0.1359],\n",
              "          [-0.1436, -0.1007, -0.1915]],\n",
              "\n",
              "         [[-0.1876,  0.0180, -0.0454],\n",
              "          [-0.0577,  0.0319,  0.1720],\n",
              "          [ 0.1050,  0.1663,  0.1276]],\n",
              "\n",
              "         [[-0.0161, -0.2008, -0.0580],\n",
              "          [ 0.1148,  0.1725, -0.1752],\n",
              "          [ 0.1025, -0.0279, -0.0751]]],\n",
              "\n",
              "\n",
              "        [[[-0.1600,  0.0226,  0.0423],\n",
              "          [-0.1064,  0.0345,  0.0705],\n",
              "          [ 0.2350,  0.0146, -0.1846]],\n",
              "\n",
              "         [[ 0.0553,  0.1268, -0.1063],\n",
              "          [ 0.1269, -0.2027, -0.2276],\n",
              "          [ 0.0790, -0.0448, -0.1781]],\n",
              "\n",
              "         [[-0.2257, -0.1416, -0.0455],\n",
              "          [-0.1524, -0.1570,  0.0389],\n",
              "          [-0.1777, -0.0986,  0.1688]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.2140, -0.2324,  0.1705],\n",
              "          [-0.0612, -0.2314, -0.1478],\n",
              "          [ 0.2043,  0.1298,  0.1255]],\n",
              "\n",
              "         [[-0.0102, -0.2335, -0.1796],\n",
              "          [ 0.0052, -0.2208, -0.0566],\n",
              "          [ 0.0173, -0.1150, -0.1643]],\n",
              "\n",
              "         [[-0.0724,  0.2352,  0.1533],\n",
              "          [ 0.1208, -0.1820, -0.0543],\n",
              "          [-0.1405,  0.2089, -0.1731]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.0151, -0.1048,  0.1156],\n",
              "          [-0.1423,  0.2094, -0.1680],\n",
              "          [-0.0326, -0.1323, -0.1038]],\n",
              "\n",
              "         [[ 0.0278,  0.1892,  0.2158],\n",
              "          [ 0.1956,  0.0455,  0.1991],\n",
              "          [ 0.2019, -0.0653, -0.1283]],\n",
              "\n",
              "         [[-0.1124, -0.1624,  0.2037],\n",
              "          [ 0.1425,  0.0466,  0.2221],\n",
              "          [ 0.1837,  0.0704,  0.1980]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1802, -0.0506,  0.0744],\n",
              "          [ 0.1718, -0.0929,  0.1551],\n",
              "          [ 0.1426,  0.0793, -0.1597]],\n",
              "\n",
              "         [[-0.1137, -0.1984,  0.2068],\n",
              "          [ 0.0726,  0.0667, -0.1335],\n",
              "          [ 0.0228,  0.1310, -0.0535]],\n",
              "\n",
              "         [[-0.2238,  0.1109,  0.0377],\n",
              "          [-0.1382,  0.0840,  0.1861],\n",
              "          [ 0.1510, -0.1958, -0.1253]]],\n",
              "\n",
              "\n",
              "        [[[-0.0821, -0.0261, -0.0671],\n",
              "          [ 0.1667, -0.1113, -0.0811],\n",
              "          [-0.0314, -0.1507, -0.2011]],\n",
              "\n",
              "         [[-0.0386, -0.2330,  0.1244],\n",
              "          [-0.1742, -0.1682,  0.1284],\n",
              "          [-0.1128,  0.1435, -0.1059]],\n",
              "\n",
              "         [[-0.1195,  0.1769, -0.1042],\n",
              "          [ 0.0231, -0.1689, -0.1440],\n",
              "          [ 0.0220,  0.1452, -0.2324]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1813, -0.0727, -0.0027],\n",
              "          [-0.1767, -0.2001, -0.1770],\n",
              "          [-0.1099, -0.1444,  0.1609]],\n",
              "\n",
              "         [[-0.1951,  0.1160, -0.1322],\n",
              "          [ 0.1317,  0.2307, -0.2299],\n",
              "          [-0.1740,  0.2345, -0.2005]],\n",
              "\n",
              "         [[ 0.2057,  0.0313, -0.1253],\n",
              "          [ 0.2239,  0.1095, -0.1002],\n",
              "          [ 0.1467, -0.1484, -0.0634]]],\n",
              "\n",
              "\n",
              "        [[[-0.2272, -0.0024, -0.0775],\n",
              "          [ 0.0834, -0.1224,  0.0455],\n",
              "          [-0.0318, -0.1834,  0.2066]],\n",
              "\n",
              "         [[ 0.2144, -0.1856, -0.0573],\n",
              "          [-0.2112,  0.2288, -0.2023],\n",
              "          [ 0.0705,  0.2048, -0.0507]],\n",
              "\n",
              "         [[ 0.1506, -0.1525,  0.0650],\n",
              "          [-0.2242, -0.1767, -0.1569],\n",
              "          [ 0.1556, -0.0069,  0.0236]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1536,  0.1411, -0.1280],\n",
              "          [-0.0710, -0.0330,  0.0083],\n",
              "          [-0.1333,  0.0935, -0.1282]],\n",
              "\n",
              "         [[-0.0821,  0.0338, -0.0766],\n",
              "          [-0.0112, -0.1254, -0.1446],\n",
              "          [ 0.1393,  0.1604,  0.1258]],\n",
              "\n",
              "         [[-0.0752,  0.0741,  0.0298],\n",
              "          [-0.0096, -0.0309,  0.2262],\n",
              "          [-0.1304,  0.1547,  0.1726]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Model"
      ],
      "metadata": {
        "id": "NSDR2BKQeqXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set the number of epochs( we will kep this small for faster trainin time)\n",
        "epochs = 3\n",
        "\n",
        "#Create training and test loop\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch:{epoch} \\n-------\")\n",
        "  ## Training\n",
        "  train_loss=0\n",
        "  #Add a loop to loop through the training batches\n",
        "  for batch, (X ,y) in enumerate(train_data):#X is image and y is label\n",
        "     model_0.train()\n",
        "\n",
        "     #1. Forward Pass\n",
        "     y_pred = model_0(X)\n",
        "\n",
        "     y = y // 2\n",
        "     #2. claculate the loss\n",
        "     loss= loss_fn(y_pred,y)\n",
        "     train_loss += loss  #acculumate train loss\n",
        "\n",
        "     #3.Optimizer zero grad\n",
        "     optimizer.zero_grad()\n",
        "\n",
        "     #4.Loss backward\n",
        "     loss.backward()\n",
        "\n",
        "     #5.optimizer Step\n",
        "     optimizer.step()\n",
        "\n",
        "     #print out whats happening\n",
        "     if batch % 400 ==0:\n",
        "       print(f\"Looked at {batch* len(X)}/ {len(train_data.dataset)} samples.\")\n",
        "  \n",
        "  ##Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_data)\n",
        "\n",
        "  ##Testing\n",
        "  test_loss, test_acc= 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in test_data:\n",
        "      #1.Forward pass\n",
        "      test_pred = model_0(X)\n",
        "      y = y//2\n",
        "      #2. Calculate loss(accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "\n",
        "      #3. calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    #Calculate the test loss average per batch\n",
        "    test_loss /= len(test_data)\n",
        "    #Calculate the test acc average per batch\n",
        "    test_acc/= len(test_data) \n",
        "\n",
        "  #print out whats happening\n",
        "  print(f\"\\n train loss: {train_loss:.4f} | Test loss:{test_loss:.4f} | test accuracy:{test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBrmgyz2m2LL",
        "outputId": "7e5f77d5-6ab7-44a3-a370-7d6ea4e214ef"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0 \n",
            "-------\n",
            "Looked at 0/ 25000 samples.\n",
            "Looked at 12800/ 25000 samples.\n",
            "\n",
            " train loss: 1.1517 | Test loss:1.2113 | test accuracy:45.5414\n",
            "Epoch:1 \n",
            "-------\n",
            "Looked at 0/ 25000 samples.\n",
            "Looked at 12800/ 25000 samples.\n",
            "\n",
            " train loss: 1.0436 | Test loss:1.2003 | test accuracy:52.8463\n",
            "Epoch:2 \n",
            "-------\n",
            "Looked at 0/ 25000 samples.\n",
            "Looked at 12800/ 25000 samples.\n",
            "\n",
            " train loss: 0.9398 | Test loss:1.1098 | test accuracy:54.6576\n"
          ]
        }
      ]
    }
  ]
}